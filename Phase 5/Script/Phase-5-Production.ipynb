{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([647.42486592])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#DD-MM-YYYY,store_nbr,item_nbr,units\n",
    "#29-07-2012  40\t5\t48\n",
    "#31-07-2012\t23\t2\t0\n",
    "#31-07-2012\t23\t3\t0\n",
    "#31-07-2012\t23\t4\t0\n",
    "#31-07-2012\t23\t5\t25\n",
    "\n",
    "#def predict():\n",
    "#setting up input\n",
    "passbackInput = ['2014-10-31', '44', '68']\n",
    "dateVal  = passbackInput[0]     \n",
    "storeVal = int(passbackInput[1])  \n",
    "itemVal  = int(passbackInput[2])\n",
    "\n",
    "#************************ Classification model **************\n",
    "#------------------------------------------------------------\n",
    "# Reading CSV files for Classification model\n",
    "path = os.getcwd()\n",
    "df_cls = pd.read_csv(os.path.join(path, \"df_Classifier_cleand.csv\"))\n",
    "#------------------------------------------------------------\n",
    "#Check if data already exsist in CSV or not\n",
    "df_chkRecord = df_cls.loc[(df_cls['date'] == dateVal) & (df_cls['store_nbr'] == storeVal) & (df_cls['item_nbr'] == itemVal)]\n",
    "#------------------------------------------------------------\n",
    "print(len(df_chkRecord))\n",
    "ActualValue = \"New data point- No previous value\"\n",
    "CheckAvailable = \"NOT AVAILABLE\"\n",
    "if len(df_chkRecord)==0:\n",
    "    df_weatherVal1 = df_cls.loc[df_cls['Month']==int(passbackInput[0].split(\"-\")[1])] \n",
    "    df_weatherVal2 = df_weatherVal1.loc[df_weatherVal1['store_nbr'] == int(storeVal)]\n",
    "    df_weatherVal_median = df_weatherVal2.median()\n",
    "    \n",
    "    QueryPoint_Dummy = df_weatherVal_median.to_frame()\n",
    "    columnLists = [\"store_nbr\",\"item_nbr\",\"station_nbr\",\"tmax\",\"depart\",\"cool\",\"snowfall\",\"preciptotal\",\"stnpressure\",\"resultspeed\",\"resultdir\",\"avgspeed\",\"Day\",\n",
    "    \"Month\",\"Holiday\",\"codesum_BCFG\",\"codesum_BLDU\",\"codesum_BLSN\",\"codesum_BR\",\"codesum_DU\",\"codesum_DZ\",\"codesum_FG\",\"codesum_FG+\",\"codesum_FU\",\n",
    "    \"codesum_FZDZ\",\"codesum_FZFG\",\"codesum_FZRA\",\"codesum_GR\",\"codesum_GS\",\"codesum_HZ\",\"codesum_MIFG\",\"codesum_PL\",\"codesum_PRFG\",\"codesum_RA\",\n",
    "    \"codesum_SG\",\"codesum_SN\",\"codesum_SQ\",\"codesum_TS\",\"codesum_TSRA\",\"codesum_TSSN\",\"codesum_UP\",\"codesum_VCFG\",\"codesum_VCTS\",\"codesum_nan\",\"units\"]\n",
    "    values = [] \n",
    "    for clmn in columnLists:\n",
    "        values.append(QueryPoint_Dummy[0][clmn])\n",
    "\n",
    "    QueryPoint = pd.DataFrame([values],columns = columnLists)\n",
    "    QueryPoint['item_nbr'] = itemVal\n",
    "else:\n",
    "    QueryPoint = df_chkRecord\n",
    "    ActualValue = str(df_chkRecord['units'])#str(df_chkRecord.get_value(0, 'units'))\n",
    "    CheckAvailable = \"AVAILABLE\"\n",
    "\n",
    "\n",
    "if 'date' in QueryPoint.columns:\n",
    "    QueryPoint.drop(['date'],axis = 1,inplace=True)\n",
    "\n",
    "if 'flag' in QueryPoint.columns:\n",
    "    QueryPoint.drop(['flag'],axis = 1,inplace=True)    \n",
    "\n",
    "#If data point exsists\n",
    "if len(df_chkRecord)==1:\n",
    "    lr = joblib.load('cls_LogisticRegrsn.pkl')\n",
    "    prediction = lr.predict(QueryPoint)\n",
    "    print(prediction[0])\n",
    "\n",
    "if ((prediction[0] == 1 & len(df_chkRecord)==1) or (len(df_chkRecord)==0)):\n",
    "    if 'units' in QueryPoint.columns:\n",
    "        QueryPoint.drop(['units'],axis = 1,inplace=True)\n",
    "   \n",
    "    #Standardize the Query point\n",
    "    #for clmn in QueryPoint.columns:\n",
    "        # fit on data column & Transform\n",
    "        #scale = StandardScaler().fit(QueryPoint[[clmn]])\n",
    "        #QueryPoint[clmn] = scale.transform(QueryPoint[[clmn]])  \n",
    "        \n",
    "    # Our best model is XGBRegressor, then Random Forest. \n",
    "    #But for both these Model- while loading pkl file we faced error in terms of Parameter so used Linear Regression  \n",
    "    reg_RF = joblib.load('LinearReg.pkl')\n",
    "    predictionReg = reg_RF.predict(QueryPoint)\n",
    "    FinalPrediction = abs(predictionReg)\n",
    "    \n",
    "elif (prediction[0] == 0) & (len(df_chkRecord)==1):\n",
    "    FinalPrediction = abs(prediction[0])\n",
    "    \n",
    "FinalPrediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>units</th>\n",
       "      <th>station_nbr</th>\n",
       "      <th>tmax</th>\n",
       "      <th>depart</th>\n",
       "      <th>cool</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>...</th>\n",
       "      <th>codesum_TSRA</th>\n",
       "      <th>codesum_TSSN</th>\n",
       "      <th>codesum_UP</th>\n",
       "      <th>codesum_VCFG</th>\n",
       "      <th>codesum_VCTS</th>\n",
       "      <th>codesum_nan</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4611769</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611844</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611871</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611938</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>39</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611946</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>39</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611951</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611991</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612073</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612125</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>41</td>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612165</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>41</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612173</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612213</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612295</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612316</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612352</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612395</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612458</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612484</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>44</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612510</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612527</th>\n",
       "      <td>2014-10-31</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  store_nbr  item_nbr  units  station_nbr  tmax  depart  \\\n",
       "4611769  2014-10-31         38        45     63           14  60.0    -7.0   \n",
       "4611844  2014-10-31         39         9     12            8  78.0     1.5   \n",
       "4611871  2014-10-31         39        36      3            8  78.0     1.5   \n",
       "4611938  2014-10-31         39       103      4            8  78.0     1.5   \n",
       "4611946  2014-10-31         39       111      2            8  78.0     1.5   \n",
       "4611951  2014-10-31         40         5     18           13  58.0     1.5   \n",
       "4611991  2014-10-31         40        45     44           13  58.0     1.5   \n",
       "4612073  2014-10-31         41        16     30           12  75.0     1.5   \n",
       "4612125  2014-10-31         41        68     15           12  75.0     1.5   \n",
       "4612165  2014-10-31         41       108      7           12  75.0     1.5   \n",
       "4612173  2014-10-31         42         5     29           14  60.0    -7.0   \n",
       "4612213  2014-10-31         42        45     35           14  60.0    -7.0   \n",
       "4612295  2014-10-31         43        16     39           11  75.0    -2.0   \n",
       "4612316  2014-10-31         43        37      8           11  75.0    -2.0   \n",
       "4612352  2014-10-31         43        73      1           11  75.0    -2.0   \n",
       "4612395  2014-10-31         44         5     47           12  75.0     1.5   \n",
       "4612458  2014-10-31         44        68     39           12  75.0     1.5   \n",
       "4612484  2014-10-31         44        94      1           12  75.0     1.5   \n",
       "4612510  2014-10-31         45         9     10           16  53.0     1.5   \n",
       "4612527  2014-10-31         45        26      1           16  53.0     1.5   \n",
       "\n",
       "         cool  snowfall  preciptotal  ...  codesum_TSRA  codesum_TSSN  \\\n",
       "4611769   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4611844   2.0       0.0          0.0  ...           0.0           0.0   \n",
       "4611871   2.0       0.0          0.0  ...           0.0           0.0   \n",
       "4611938   2.0       0.0          0.0  ...           0.0           0.0   \n",
       "4611946   2.0       0.0          0.0  ...           0.0           0.0   \n",
       "4611951   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4611991   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612073   3.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612125   3.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612165   3.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612173   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612213   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612295   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612316   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612352   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612395   3.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612458   3.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612484   3.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612510   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "4612527   0.0       0.0          0.0  ...           0.0           0.0   \n",
       "\n",
       "         codesum_UP  codesum_VCFG  codesum_VCTS  codesum_nan  Day  Month  \\\n",
       "4611769         0.0           0.0           0.0          1.0   31     10   \n",
       "4611844         0.0           0.0           0.0          0.0   31     10   \n",
       "4611871         0.0           0.0           0.0          0.0   31     10   \n",
       "4611938         0.0           0.0           0.0          0.0   31     10   \n",
       "4611946         0.0           0.0           0.0          0.0   31     10   \n",
       "4611951         0.0           0.0           0.0          1.0   31     10   \n",
       "4611991         0.0           0.0           0.0          1.0   31     10   \n",
       "4612073         0.0           0.0           0.0          0.0   31     10   \n",
       "4612125         0.0           0.0           0.0          0.0   31     10   \n",
       "4612165         0.0           0.0           0.0          0.0   31     10   \n",
       "4612173         0.0           0.0           0.0          1.0   31     10   \n",
       "4612213         0.0           0.0           0.0          1.0   31     10   \n",
       "4612295         0.0           0.0           0.0          1.0   31     10   \n",
       "4612316         0.0           0.0           0.0          1.0   31     10   \n",
       "4612352         0.0           0.0           0.0          1.0   31     10   \n",
       "4612395         0.0           0.0           0.0          0.0   31     10   \n",
       "4612458         0.0           0.0           0.0          0.0   31     10   \n",
       "4612484         0.0           0.0           0.0          0.0   31     10   \n",
       "4612510         0.0           0.0           0.0          1.0   31     10   \n",
       "4612527         0.0           0.0           0.0          1.0   31     10   \n",
       "\n",
       "         Holiday  flag  \n",
       "4611769    False     1  \n",
       "4611844    False     1  \n",
       "4611871    False     1  \n",
       "4611938    False     1  \n",
       "4611946    False     1  \n",
       "4611951    False     1  \n",
       "4611991    False     1  \n",
       "4612073    False     1  \n",
       "4612125    False     1  \n",
       "4612165    False     1  \n",
       "4612173    False     1  \n",
       "4612213    False     1  \n",
       "4612295    False     1  \n",
       "4612316    False     1  \n",
       "4612352    False     1  \n",
       "4612395    False     1  \n",
       "4612458    False     1  \n",
       "4612484    False     1  \n",
       "4612510    False     1  \n",
       "4612527    False     1  \n",
       "\n",
       "[20 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls[df_cls['units']>0].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[19:31:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:959: Check failed: header == serialisation_header_: \n\n  If you are loading a serialized model (like pickle in Python) generated by older\n  XGBoost, please export the model by calling `Booster.save_model` from that version\n  first, then load it back in current version.  There's a simple script for helping\n  the process. See:\n\n    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n\n  for reference to the script, and more details about differences between saving model and\n  serializing.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1366ec8ac6e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;31m# Our best model is XGBRegressor, then Random Forest.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m#But for both these Model- while loading pkl file we faced error in terms of Parameter so used Linear Regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0mreg_RF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regrsn_XGBRegressor.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mpredictionReg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_RF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQueryPoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mFinalPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictionReg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    583\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1208\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1210\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1211\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[0mNDArrayWrapper\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mUnpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# For backward compatibility, we support NDArrayWrapper objects.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1701\u001b[0m         \u001b[0msetstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__setstate__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msetstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1703\u001b[1;33m             \u001b[0msetstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1704\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m         \u001b[0mslotstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m   1449\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m             \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1451\u001b[1;33m             _check_call(\n\u001b[0m\u001b[0;32m   1452\u001b[0m                 _LIB.XGBoosterUnserializeFromBuffer(handle, ptr, length))\n\u001b[0;32m   1453\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'handle'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \"\"\"\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [19:31:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:959: Check failed: header == serialisation_header_: \n\n  If you are loading a serialized model (like pickle in Python) generated by older\n  XGBoost, please export the model by calling `Booster.save_model` from that version\n  first, then load it back in current version.  There's a simple script for helping\n  the process. See:\n\n    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n\n  for reference to the script, and more details about differences between saving model and\n  serializing.\n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#DD-MM-YYYY,store_nbr,item_nbr,units\n",
    "#29-07-2012  40\t5\t48\n",
    "#31-07-2012\t23\t2\t0\n",
    "#31-07-2012\t23\t3\t0\n",
    "#31-07-2012\t23\t4\t0\n",
    "#31-07-2012\t23\t5\t25\n",
    "\n",
    "#def predict():\n",
    "#setting up input\n",
    "passbackInput = ['2014-10-31', '44', '68']\n",
    "dateVal  = passbackInput[0]     \n",
    "storeVal = int(passbackInput[1])  \n",
    "itemVal  = int(passbackInput[2])\n",
    "\n",
    "#************************ Classification model **************\n",
    "#------------------------------------------------------------\n",
    "# Reading CSV files for Classification model\n",
    "path = os.getcwd()\n",
    "df_cls = pd.read_csv(os.path.join(path, \"df_Classifier_cleand.csv\"))\n",
    "#------------------------------------------------------------\n",
    "#Check if data already exsist in CSV or not\n",
    "df_chkRecord = df_cls.loc[(df_cls['date'] == dateVal) & (df_cls['store_nbr'] == storeVal) & (df_cls['item_nbr'] == itemVal)]\n",
    "#------------------------------------------------------------\n",
    "print(len(df_chkRecord))\n",
    "ActualValue = \"New data point- No previous value\"\n",
    "CheckAvailable = \"NOT AVAILABLE\"\n",
    "if len(df_chkRecord)==0:\n",
    "    df_weatherVal1 = df_cls.loc[df_cls['Month']==int(passbackInput[0].split(\"-\")[1])] \n",
    "    df_weatherVal2 = df_weatherVal1.loc[df_weatherVal1['store_nbr'] == int(storeVal)]\n",
    "    df_weatherVal_median = df_weatherVal2.median()\n",
    "    \n",
    "    QueryPoint_Dummy = df_weatherVal_median.to_frame()\n",
    "    columnLists = [\"store_nbr\",\"item_nbr\",\"station_nbr\",\"tmax\",\"depart\",\"cool\",\"snowfall\",\"preciptotal\",\"stnpressure\",\"resultspeed\",\"resultdir\",\"avgspeed\",\"Day\",\n",
    "    \"Month\",\"Holiday\",\"codesum_BCFG\",\"codesum_BLDU\",\"codesum_BLSN\",\"codesum_BR\",\"codesum_DU\",\"codesum_DZ\",\"codesum_FG\",\"codesum_FG+\",\"codesum_FU\",\n",
    "    \"codesum_FZDZ\",\"codesum_FZFG\",\"codesum_FZRA\",\"codesum_GR\",\"codesum_GS\",\"codesum_HZ\",\"codesum_MIFG\",\"codesum_PL\",\"codesum_PRFG\",\"codesum_RA\",\n",
    "    \"codesum_SG\",\"codesum_SN\",\"codesum_SQ\",\"codesum_TS\",\"codesum_TSRA\",\"codesum_TSSN\",\"codesum_UP\",\"codesum_VCFG\",\"codesum_VCTS\",\"codesum_nan\",\"units\"]\n",
    "    values = [] \n",
    "    for clmn in columnLists:\n",
    "        values.append(QueryPoint_Dummy[0][clmn])\n",
    "\n",
    "    QueryPoint = pd.DataFrame([values],columns = columnLists)\n",
    "    QueryPoint['item_nbr'] = itemVal\n",
    "else:\n",
    "    QueryPoint = df_chkRecord\n",
    "    ActualValue = str(df_chkRecord['units'])#str(df_chkRecord.get_value(0, 'units'))\n",
    "    CheckAvailable = \"AVAILABLE\"\n",
    "\n",
    "\n",
    "if 'date' in QueryPoint.columns:\n",
    "    QueryPoint.drop(['date'],axis = 1,inplace=True)\n",
    "\n",
    "if 'flag' in QueryPoint.columns:\n",
    "    QueryPoint.drop(['flag'],axis = 1,inplace=True)    \n",
    "\n",
    "#If data point exsists\n",
    "if len(df_chkRecord)==1:\n",
    "    lr = joblib.load('cls_LogisticRegrsn.pkl')\n",
    "    prediction = lr.predict(QueryPoint)\n",
    "    print(prediction[0])\n",
    "\n",
    "if ((prediction[0] == 1 & len(df_chkRecord)==1) or (len(df_chkRecord)==0)):\n",
    "    if 'units' in QueryPoint.columns:\n",
    "        QueryPoint.drop(['units'],axis = 1,inplace=True)\n",
    "   \n",
    "    #Standardize the Query point\n",
    "    #for clmn in QueryPoint.columns:\n",
    "        # fit on data column & Transform\n",
    "        #scale = StandardScaler().fit(QueryPoint[[clmn]])\n",
    "        #QueryPoint[clmn] = scale.transform(QueryPoint[[clmn]])  \n",
    "        \n",
    "    # Our best model is XGBRegressor, then Random Forest. \n",
    "    #But for both these Model- while loading pkl file we faced error in terms of Parameter so used Linear Regression  \n",
    "    reg_RF = joblib.load('regrsn_XGBRegressor.pkl')\n",
    "    predictionReg = reg_RF.predict(QueryPoint)\n",
    "    FinalPrediction = abs(predictionReg)\n",
    "    \n",
    "elif (prediction[0] == 0) & (len(df_chkRecord)==1):\n",
    "    FinalPrediction = abs(prediction[0])\n",
    "    \n",
    "FinalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeRegressor' object has no attribute 'n_features_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1ced345783ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m#But for both these Model- while loading pkl file we faced error in terms of Parameter so used Linear Regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mreg_RF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RandomForestRegressor.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mpredictionReg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_RF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQueryPoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[0mFinalPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictionReg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m             raise ValueError(\"Number of features of the model must \"\n\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DecisionTreeRegressor' object has no attribute 'n_features_'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#DD-MM-YYYY,store_nbr,item_nbr,units\n",
    "#29-07-2012  40\t5\t48\n",
    "#31-07-2012\t23\t2\t0\n",
    "#31-07-2012\t23\t3\t0\n",
    "#31-07-2012\t23\t4\t0\n",
    "#31-07-2012\t23\t5\t25\n",
    "\n",
    "#def predict():\n",
    "#setting up input\n",
    "passbackInput = ['2014-10-31', '44', '68']\n",
    "dateVal  = passbackInput[0]     \n",
    "storeVal = int(passbackInput[1])  \n",
    "itemVal  = int(passbackInput[2])\n",
    "\n",
    "#************************ Classification model **************\n",
    "#------------------------------------------------------------\n",
    "# Reading CSV files for Classification model\n",
    "path = os.getcwd()\n",
    "df_cls = pd.read_csv(os.path.join(path, \"df_Classifier_cleand.csv\"))\n",
    "#------------------------------------------------------------\n",
    "#Check if data already exsist in CSV or not\n",
    "df_chkRecord = df_cls.loc[(df_cls['date'] == dateVal) & (df_cls['store_nbr'] == storeVal) & (df_cls['item_nbr'] == itemVal)]\n",
    "#------------------------------------------------------------\n",
    "print(len(df_chkRecord))\n",
    "ActualValue = \"New data point- No previous value\"\n",
    "CheckAvailable = \"NOT AVAILABLE\"\n",
    "if len(df_chkRecord)==0:\n",
    "    df_weatherVal1 = df_cls.loc[df_cls['Month']==int(passbackInput[0].split(\"-\")[1])] \n",
    "    df_weatherVal2 = df_weatherVal1.loc[df_weatherVal1['store_nbr'] == int(storeVal)]\n",
    "    df_weatherVal_median = df_weatherVal2.median()\n",
    "    \n",
    "    QueryPoint_Dummy = df_weatherVal_median.to_frame()\n",
    "    columnLists = [\"store_nbr\",\"item_nbr\",\"station_nbr\",\"tmax\",\"depart\",\"cool\",\"snowfall\",\"preciptotal\",\"stnpressure\",\"resultspeed\",\"resultdir\",\"avgspeed\",\"Day\",\n",
    "    \"Month\",\"Holiday\",\"codesum_BCFG\",\"codesum_BLDU\",\"codesum_BLSN\",\"codesum_BR\",\"codesum_DU\",\"codesum_DZ\",\"codesum_FG\",\"codesum_FG+\",\"codesum_FU\",\n",
    "    \"codesum_FZDZ\",\"codesum_FZFG\",\"codesum_FZRA\",\"codesum_GR\",\"codesum_GS\",\"codesum_HZ\",\"codesum_MIFG\",\"codesum_PL\",\"codesum_PRFG\",\"codesum_RA\",\n",
    "    \"codesum_SG\",\"codesum_SN\",\"codesum_SQ\",\"codesum_TS\",\"codesum_TSRA\",\"codesum_TSSN\",\"codesum_UP\",\"codesum_VCFG\",\"codesum_VCTS\",\"codesum_nan\",\"units\"]\n",
    "    values = [] \n",
    "    for clmn in columnLists:\n",
    "        values.append(QueryPoint_Dummy[0][clmn])\n",
    "\n",
    "    QueryPoint = pd.DataFrame([values],columns = columnLists)\n",
    "    QueryPoint['item_nbr'] = itemVal\n",
    "else:\n",
    "    QueryPoint = df_chkRecord\n",
    "    ActualValue = str(df_chkRecord['units'])#str(df_chkRecord.get_value(0, 'units'))\n",
    "    CheckAvailable = \"AVAILABLE\"\n",
    "\n",
    "\n",
    "if 'date' in QueryPoint.columns:\n",
    "    QueryPoint.drop(['date'],axis = 1,inplace=True)\n",
    "\n",
    "if 'flag' in QueryPoint.columns:\n",
    "    QueryPoint.drop(['flag'],axis = 1,inplace=True)    \n",
    "\n",
    "#If data point exsists\n",
    "if len(df_chkRecord)==1:\n",
    "    lr = joblib.load('cls_LogisticRegrsn.pkl')\n",
    "    prediction = lr.predict(QueryPoint)\n",
    "    print(prediction[0])\n",
    "\n",
    "if ((prediction[0] == 1 & len(df_chkRecord)==1) or (len(df_chkRecord)==0)):\n",
    "    if 'units' in QueryPoint.columns:\n",
    "        QueryPoint.drop(['units'],axis = 1,inplace=True)\n",
    "   \n",
    "    #Standardize the Query point\n",
    "    #for clmn in QueryPoint.columns:\n",
    "        # fit on data column & Transform\n",
    "        #scale = StandardScaler().fit(QueryPoint[[clmn]])\n",
    "        #QueryPoint[clmn] = scale.transform(QueryPoint[[clmn]])  \n",
    "        \n",
    "    # Our best model is XGBRegressor, then Random Forest. \n",
    "    #But for both these Model- while loading pkl file we faced error in terms of Parameter so used Linear Regression  \n",
    "    reg_RF = joblib.load('RandomForestRegressor.pkl')\n",
    "    predictionReg = reg_RF.predict(QueryPoint)\n",
    "    FinalPrediction = abs(predictionReg)\n",
    "    \n",
    "elif (prediction[0] == 0) & (len(df_chkRecord)==1):\n",
    "    FinalPrediction = abs(prediction[0])\n",
    "    \n",
    "FinalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
